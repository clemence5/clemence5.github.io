---
title: "Machine Learning Project: Wine Data Set"
date: 2019-09-02
tags: [machine learning, data science, random forest, TPOT, decision tree, decision trees, gradient boost, Xtreme gradient boosting, XGBoost, scikit-learn, sklearn]
excerpt: "Machine Learning, Wine, Data Science"
header:
  overlay_image: "/images/wine/tyrion.jpg"
  overlay_filter: 0.5
  actions:
    - label: "View on Google Colab"
      url: "https://colab.research.google.com/drive/12Nx7W-RSRLgA0EZ9u4DPVc3HrtpN3luu#scrollTo=B6ROuYD_qbap&forceEdit=true&offline=true&sandboxMode=true"
mathjax: true
---

# Classifying Red Wine with Machine Learning  


## Dataset:
The dataset, which is hosted and kindly provided free of charge by the [UCI Machine Learning Repository](http://mlr.cs.umass.edu/ml/), is of red wine from [Vinho Verde](http://www.vinhoverde.pt/en/about-vinho-verde) in Portugal

In a [colab](https://colab.research.google.com/)/[kaggle](https://www.kaggle.com/)/[Jupyter](https://jupyter.org/) notebook, We load a csv file containing our dataset from the UCI ML repository
and quickly view our dataset like so:

### Load dataset
```python
import numpy as np  # For array manipulation
import pandas as pd # For easily viewing and manipulating dataframes
dataset_url = 'http://mlr.cs.umass.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'
data = pd.read_csv(dataset_url, sep=';')
data.head()
```

* Insert Code output image here *

Here we see the first a bunch of labeled columns, from **fixed acidity** to **quality**, and the first 5 rows of the dataset.

## Aim:
We want to predict the quality of red wine given the following attributes:
* fixed acidity
* volatile acidity
* citric acid
* residual sugar
* chlorides
* free sulfur dioxide
* total sulfur dioxide
* density
* pH
* sulphates
and
* alcohol


## Exploratory Data Analysis
Let's take a closer look at the dataset. We start by separating the target column, *quality* from the features:

```python
target = data.quality # The targets column
X = data.drop('quality', axis=1) # features

print('\nOur data has %d observations and %d features\n' %(X.shape[0], X.shape[1]))

#columns with missing data
print('Are there missing observations the columns?\n', (data.isnull().any()))

print('\nThere are', target.nunique(), 'Unique values for quality, namely:', sorted(target.unique()))
```
We see that our data has 1599 observations and 11 features. None of the columns contain any missing variables, which makes our task a lot easier.

The $\texttt{target.nunique()}$ and $\texttt{target.unique}$ commands give us the number and values of all the unique entries in the target column.
We see that our data contains 6 wine qualities: 3, 4, 5, 6, 7 and 8.

How are the 1599 wines distributed in quality?
```python
vgq = data[target>6]  #top tier quality
aq = data[(target>=5) & (target<=6)]  #average quality
bq = data[target<5]   #bad quality

print('%.2f %% of the wines are of top tier quality' %(100*len(vgq)/len(target)))
print('%.2f %% of the wines are of average quality' %(100*len(aq)/len(target)))
print('%.2f %% of the wines are below average quality' %(100*len(bq)/len(target)))
```

$13.57\%$ of the wines are are of top tier quality, i.e they have a quality of 7 or 8. The bulk ($82.49\%$) of the wine is of comparatively average quality while $3.94\%$ are below average in quality.

Numbers are cool, but graphics make more sense to most of us. What does the wine quality distribution look like in a ~histogram~ bar graph?

```python
import matplotlib.pyplot # The go-to library for plotting in python
import seaborn as sns # Another powerful library for pretty and useful visualisations
sns.set() #initialise seaborn so that all our plots are exciting by default


sns.distplot(target, norm_hist=False, kde=False)
plt.title('Wine quality feature distribution')
plt.ylabel('Number of observations')
plt.show()
```

**image here**

We see from the bar graph that indeed most of the wines are of average quality, less than half are above average while even fewer are below average.

However, we are interested in the excellent quality wines. Let's therefore separate the wines of excellent quality ($\geq 7$) from the rest. We will be building classifiers, given the 11 features, that separate/identify excellent quality wine from the rest.

Let's begin by creating a column of binary values in the features dataframe X, which indicates whether the wine is of excellent (1) or less than excellent quality (0):
```python
XX = X.copy() # To be safe, let's only modify a copy of the features DF

XX['best_quality'] = 1
XX['best_quality'][target<7] = 0 # All wines less than excellent

XX.describe()
```

The $\texttt{XX.describe}$ command gives us a summary of the statistics of each column in $\texttt{XX}$.

Now we have only two classes of wine. This pie chart shows us how our raw data is distributed in wine based on the two classes we defined:
```python
plt.pie(XX.best_quality.value_counts(), autopct='%1.2f%%', colors=['r', 'b'])
plt.legend(labels=['Average', 'Excellent'], loc='best')
plt.title('Wine Quality Pie Chart')
plt.show()
```

Our problem is thus:

Given the features in $\texttt{XX.columns.values}$, we want to predict whether or not a wine will be of excellent quality

```python
# The targets are now composed of 2 classes (excellent and not excellent)
y = XX.best_quality
# Let's drop the targets column from the features dataframe
XX = XX.drop(['best_quality'], axis=1)
```

Before we proceed to the next step, Let's have a look at the correlations between our features

The features we train our data on should not be too correlated with each other, to avoid [Multicollinearity](https://en.wikipedia.org/wiki/Multicollinearity), a key assumption in Linear Regression analysis which could also be an issue in [Classification problems](https://stats.stackexchange.com/questions/266267/should-one-be-concerned-about-multi-collinearity-when-using-non-linear-models/352760)

```python
pd.plotting.scatter_matrix(XX, alpha = 0.3, figsize = (60,40), diagonal = 'kde');
```

```python
correlation = data.corr()
plt.figure(figsize=(14,12))
plt.title('Correlation')
sns.heatmap(correlation, annot=True, linewidths=0, vmin=-1, cmap="RdBu_r")
plt.show()
```

There is no consensus on what the correlation threshold for multicollinearity should be, and thus this might just be down to trial and error.

We will first train our models with all the features and later check if we can somehow increase model accuracy by addressing the highest correlations.


# Preprocessing

## Train-test-split
We must split our data into a training set and a validation/test set. The test set is set to be a small fraction of the observations, and the rest is used for training.
The train_test_split module from scikit-learn does just that job for us. specifying the test size automatically tells $\texttt{train_test_split}$ to make the remaining data the training set, and vice-versa.

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(XX, y, test_size=0.25,
                                                   random_state=0, stratify=y)
```


```python
# Do we have any categorical variables in our features?
cat = [cname for cname in XX.columns if XX[cname].dtype=='object']
print('There are %d columns with categorical entries\n' %len(cat))
```
Raw data usually comes with a lot of missing, unreliable entries, as well as data of different types. We ideally want all our data to be numerical, and at the same scale, for comparability.
Since our data contains no missing or categorical values (phew!), the entire Preprocessing process will entail standardizing the data. We do this, for each column, by taking each observation X and transforming it according to:
$$z =  \frac{X-\mu }{\sigma}$$

In this case we are going to perform all the preprocessing inside the ML models' pipelines.
Speaking of which...

# Models

We will try multiple ML classifier algorithms and evaluate their performance to select the best model for our problem.

We will try training the following algorithms on our data:

A Decision Tree Classifier

A Random Forest ensemble Classifier

and the eXtreme Gradient Boosting Classifier

```python
print('Defining the Classifiers and fitting them on our training data...')

decTree_pipeline = Pipeline(steps=[('preprocessor', preprocessing.StandardScaler()),
                                   ('model', DecisionTreeClassifier(random_state=0))])
decTree_pipeline.fit(X_train, y_train)

RF = Pipeline(steps=[('preprocessor', preprocessing.StandardScaler()),
                     ('model', RandomForestClassifier(n_estimators=1000, random_state=0))])
RF.fit(X_train, y_train)


xgb = Pipeline(steps=[('preprocessor', preprocessing.StandardScaler()),
              ('model', xgboost.XGBClassifier(n_estimators=1000, learning_rate=0.05))])
xgb.fit(X_train, y_train)

print('...\nDone!')
```

To do: 5\% of this article's text and code, images


Stay in touch for more data science hijinks!
